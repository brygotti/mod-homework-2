{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "#### EE-556 Mathematics of Data - Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework covers Lectures 8-12. Please take a look at the material for the context and notation.\n",
    "\n",
    "In this homework we will study minimax problems. We will begin with some theoretical analysis and in a second part you will implement a Wasserstein Generative Adversarial Network (WGAN). \n",
    "\n",
    "These notebooks should expose you to the fundamentals of GAN training at a basic level, as well as some of the theory behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Minimax problems - 65 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Theoretical recap: stationary points and convergence in minmax games - 25 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a stylized function $f:\\mathbb{R}^4 \\to \\mathbb{R}$ with variables $x_1,x_2,y_1,y_2$, we denote by\n",
    "$x=(x_1,x_2) \\in \\mathbb{R}^2$, $y=(y_1,y_2) \\in \\mathbb{R}^2$, the function has the form of\n",
    "$\n",
    "f(x,y) = (a x - b)^\\top (a y - c), \\quad a \\neq 0, \\; b,c \\in \\mathbb{R}^2.\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1)__ (5 points) Write down the first-order stationary points of $f$, and\n",
    "        classify them as local minimum, local maximum, or saddle point by\n",
    "        inspecting its Hessian.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_x f(x,y) = a (a y - c), \\quad \\nabla_y f(x,y) = a (a x - b)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Setting the gradients to zero, we see that there is a single stationary point given by:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a (a y - c) = 0 \\iff y = \\frac{c}{a}, \\quad a (a x - b) = 0 \\iff x = \\frac{b}{a}\n",
    "\\end{aligned}\n",
    "$$\n",
    "We know that the gradient is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla f(x,y) = \\begin{bmatrix}\n",
    "\\nabla_x f(x,y) \\\\\n",
    "\\nabla_y f(x,y)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a (a y - c) \\\\\n",
    "a (a x - b)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a^2 y_1 - a c_1 \\\\\n",
    "a^2 y_2 - a c_2 \\\\\n",
    "a^2 x_1 - a b_1 \\\\\n",
    "a^2 x_2 - a b_2\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Thus the Hessian is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H = J_{\\nabla f} (x,y) = \\begin{bmatrix}\n",
    "0 & 0 & a^2 & 0 \\\\\n",
    "0 & 0 & 0 & a^2 \\\\\n",
    "a^2 & 0 & 0 & 0 \\\\\n",
    "0 & a^2 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Eigenvectors of $H$ are given by:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(1,0,1,0)^\\top, \\quad (0,1,0,1)^\\top &\\text{ with eigenvalue } a^2 \\\\\n",
    "(1,0,-1,0)^\\top, \\quad (0,1,0,-1)^\\top &\\text{ with eigenvalue } -a^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "Thus there are 2 directions of positive curvature and 2 directions of negative curvature, implying that the stationary point is a saddle point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(2)__ (5 points) Find the solution $(x^\\star,y^\\star)$ to the\n",
    "        minimax problem $\\min_x \\max_y f(x, y)$. You can quantify the solution\n",
    "        by using the following saddle point inequality:  $f(x^\\star, y^\\star)\n",
    "        \\geq f(x^\\star, y)$ and $f(x^\\star, y^\\star) \\leq f(x, y^\\star)$, for\n",
    "        all $x, y$.\n",
    "        \n",
    "**HINT:** $(x^\\star, y^\\star)$ can only be one of the critical points you found in (1), just evaluate $f$ at every place in the inequalities to check the optimality!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prove that if there exists a point $(x^\\star, y^\\star)$ satisfying the saddle point inequalities, then that point is a solution to the minimax problem.\n",
    "\n",
    "For that we first need to prove that for any given minimax problem $\\min_x \\max_y f(x,y)$, the following property holds:\n",
    "$$\n",
    "\\min_x \\max_y f(x,y) \\geq \\max_y \\min_x f(x,y)\n",
    "$$\n",
    "This property is known as weak duality. The proof is as follows:\n",
    "1. For any fixed $y$, we have that $\\max_{\\hat{y}} f(x, \\hat{y}) \\geq f(x,y)$ holds $\\forall x$ trivially by definition of $\\max_{\\hat{y}}$.\n",
    "2. Now we can lower bound the right-hand side: $\\max_{\\hat{y}} f(x, \\hat{y}) \\geq \\min_{\\hat{x}} f(\\hat{x}, y)$ is still true $\\forall x$.\n",
    "3. Now pick the $x$ that minimizes the left-hand side, yielding: $\\min_{\\hat{x}} \\max_{\\hat{y}} f(\\hat{x}, \\hat{y}) \\geq \\min_{\\hat{x}} f(\\hat{x}, y)$.\n",
    "4. Finally, since the inequality holds for any fixed $y$, we can pick the $y$ that maximizes the right-hand side, yielding the desired result:\n",
    "$$\n",
    "\\min_{\\hat{x}} \\max_{\\hat{y}} f(\\hat{x}, \\hat{y}) \\geq \\max_{\\hat{y}} \\min_{\\hat{x}} f(\\hat{x}, \\hat{y})\n",
    "$$\n",
    "\n",
    "Now that we have established weak duality, we can proceed to prove that if a saddle point $(x^\\star, y^\\star)$ exists, it is indeed a solution to the minimax problem.\n",
    "\n",
    "Let $(x^\\star, y^\\star)$ be a point satisfying the saddle point inequalities:\n",
    "$$\n",
    "f(x^\\star, y) \\leq f(x^\\star, y^\\star) \\leq f(x, y^\\star), \\quad \\forall x, y\n",
    "$$\n",
    "\n",
    "By maximizing the left inequality over $y$, and minimizing the right inequality over $x$, we obtain:\n",
    "$$\n",
    "\\max_y f(x^\\star, y) \\leq f(x^\\star, y^\\star) \\leq \\min_x f(x, y^\\star)\n",
    "$$\n",
    "\n",
    "We also know trivially that:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_x \\max_y f(x,y) \\leq \\max_y f(x^\\star, y) \\quad \\text{(a)} \\\\\n",
    "\\min_x f(x, y^\\star) \\leq \\max_y \\min_x f(x,y) \\quad \\text{(b)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Given that $x^\\star$ is a possible choice for $x$ in the minimization in (a), and $y^\\star$ is a possible choice for $y$ in the maximization in (b).\n",
    "Combining these inequalities, we have:\n",
    "$$\n",
    "\\min_x \\max_y f(x,y) \\leq \\max_y f(x^\\star, y) \\leq f(x^\\star, y^\\star) \\leq \\min_x f(x, y^\\star) \\leq \\max_y \\min_x f(x,y)\n",
    "$$\n",
    "\n",
    "By weak duality, we know that $\\min_x \\max_y f(x,y) \\geq \\max_y \\min_x f(x,y)$, thus all inequalities must be equalities, yielding:\n",
    "$$\n",
    "\\min_x \\max_y f(x,y) = f(x^\\star, y^\\star) = \\max_y \\min_x f(x,y)\n",
    "$$\n",
    "\n",
    "Thus, $(x^\\star, y^\\star)$ is indeed a solution to the minimax problem.\n",
    "\n",
    "We also know that the saddle point inequalities imply that $(x^\\star, y^\\star)$ is a stationary point of $f$. This is because $y^\\star$ maximizes $f(x^\\star, y)$ over $y$, and thus the gradient with respect to $y$ must be zero at that point. Similarly, $x^\\star$ minimizes $f(x, y^\\star)$ over $x$, and thus the gradient with respect to $x$ must also be zero at that point. Therefore, we have:\n",
    "$$\n",
    "\\nabla_x f(x^\\star, y^\\star) = 0, \\quad \\nabla_y f(x^\\star, y^\\star) = 0\n",
    "$$\n",
    "\n",
    "Thus, our only candidate for a point satisfying the saddle point inequalities is the stationary point found in (1).\n",
    "\n",
    "Evaluating the saddle point inequalities at the stationary point $(\\hat{x}, \\hat{y}) = \\left(\\frac{b}{a}, \\frac{c}{a}\\right)$, we have:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f\\left(\\hat{x}, \\hat{y}\\right) = (a \\cdot \\frac{b}{a} - b)^\\top (a \\cdot \\frac{c}{a} - c) = 0^\\top 0 = 0 \\\\\n",
    "f\\left(\\hat{x}, y\\right) = (a \\cdot \\frac{b}{a} - b)^\\top (a y - c) = 0^\\top (a y - c) = 0 \\\\\n",
    "f\\left(x, \\hat{y}\\right) = (a x - b)^\\top (a \\cdot \\frac{c}{a} - c) = (a x - b)^\\top 0 = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the saddle point inequalities hold for the point $(\\hat{x}, \\hat{y})$:\n",
    "$$\n",
    "f\\left(\\hat{x}, y\\right) = 0 \\leq 0 = f\\left(\\hat{x}, \\hat{y}\\right) \\leq 0 = f\\left(x, \\hat{y}\\right), \\quad \\forall x, y\n",
    "$$\n",
    "\n",
    "Therefore, a solution to the minimax problem is:\n",
    "$$\n",
    "(x^\\star, y^\\star) = \\left(\\frac{b}{a}, \\frac{c}{a}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(3)__ (15 points) One possible attempt at finding this solution via iterative\n",
    "        first-order methods is to perform gradient updates on the variables $x$\n",
    "        and $y$. More precisely for $\\gamma > 0$ consider the simultaneous gradient\n",
    "        descent/ascent updates\n",
    "        \n",
    "\\begin{equation}\n",
    "    x^{k+1} = x^k - \\gamma \\nabla_x f(x^k, y^k), \\qquad\n",
    "    y^{k+1} = y^k + \\gamma \\nabla_y f(x^k, y^k) \\nonumber\n",
    "\\end{equation}\n",
    "Show that the sequence of iterates $\\{x^k, y^k \\}_{k=0}^\\infty$ starting\n",
    "from any point $(x^0, y^0) \\neq (x^\\star, y^\\star)$ diverges, for any $\\gamma > 0$.\n",
    "Find the rate at which the distance from \n",
    "$(x^\\star,y^\\star)$ to the sequence $\\{x^k, y^k \\}$ grows as the number of iterations $k$ increases.\n",
    "\n",
    "**HINT:** Define $d_k^2=||(x^k,y^k)-(x^\\star, y^\\star)||_2^2$ as the sequence of squared distances to the optimum. If you find a formula for how $d_{k+1}$ depends on $d_k$ using the exact gradient updates for our $f$, you can easily argue for the divergence and the rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have that:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d_{k+1}^2 &= ||(x^{k+1},y^{k+1})-(x^\\star, y^\\star)||_2^2 \\\\\n",
    "&= ||(x^k - \\gamma \\nabla_x f(x^k, y^k), y^k + \\gamma \\nabla_y f(x^k, y^k))-(x^\\star, y^\\star)||_2^2 \\\\\n",
    "&= ||(x^k,y^k)-(x^\\star, y^\\star) - \\gamma (\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k))||_2^2 \\\\\n",
    "&= \\langle (x^k,y^k)-(x^\\star, y^\\star) - \\gamma (\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k)), (x^k,y^k)-(x^\\star, y^\\star) - \\gamma (\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k)) \\rangle \\\\\n",
    "&= ||(x^k,y^k)-(x^\\star, y^\\star)||_2^2 + \\gamma^2 ||(\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k))||_2^2\n",
    "- 2 \\gamma \\langle (x^k,y^k)-(x^\\star, y^\\star), (\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k)) \\rangle\n",
    "\\end{aligned}\n",
    "$$\n",
    "We know from point (1) that:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_x f(x,y) = a (a y - c), \\quad \\nabla_y f(x,y) = a (a x - b)\n",
    "\\end{aligned}\n",
    "$$\n",
    "And from point (2) that:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x^\\star = \\frac{b}{a}, \\quad y^\\star = \\frac{c}{a}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Thus:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "||(\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k))||_2^2 &= ||(a (a y^k - c), -a (a x^k - b))||_2^2 \\\\\n",
    "&= a^2 ||(a y^k - c, -(a x^k - b))||_2^2 \\\\\n",
    "&= a^2 (||a y^k - c||_2^2 + ||a x^k - b||_2^2) \\\\\n",
    "&= a^2 (||a (y^k - \\frac{c}{a})||_2^2 + ||a (x^k - \\frac{b}{a})||_2^2) \\\\\n",
    "&= a^2 (||a (y^k - y^\\star)||_2^2 + ||a (x^k - x^\\star)||_2^2) \\\\\n",
    "&= a^4 (||y^k - y^\\star||_2^2 + ||x^k - x^\\star||_2^2) \\\\\n",
    "&= a^4 d_k^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "And:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle (x^k,y^k)-(x^\\star, y^\\star), (\\nabla_x f(x^k, y^k), -\\nabla_y f(x^k, y^k)) \\rangle &= \\langle (x^k - x^\\star, y^k - y^\\star), (a (a y^k - c), -a (a x^k - b)) \\rangle \\\\\n",
    "&= \\langle (x^k - x^\\star, y^k - y^\\star), (a^2 (y^k - \\frac{c}{a}), -a^2 (x^k - \\frac{b}{a})) \\rangle \\\\\n",
    "&= \\langle (x^k - x^\\star, y^k - y^\\star), (a^2 (y^k - y^\\star), -a^2 (x^k - x^\\star)) \\rangle \\\\\n",
    "&= a^2 \\langle (x^k - x^\\star, y^k - y^\\star), (y^k - y^\\star, -(x^k - x^\\star)) \\rangle \\\\\n",
    "&= a^2 ( \\langle x^k - x^\\star, y^k - y^\\star \\rangle - \\langle y^k - y^\\star, x^k - x^\\star \\rangle ) \\\\\n",
    "&= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "So we get:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d_{k+1}^2 &= d_k^2 + \\gamma^2 a^4 d_k^2 - 2 \\gamma \\cdot 0 \\\\\n",
    "&= (1 + \\gamma^2 a^4) d_k^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "This means that\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d_k^2 = (1 + \\gamma^2 a^4)^k d_0^2 \\quad \\text{ and } \\quad d_k = (1 + \\gamma^2 a^4)^{\\frac{k}{2}} d_0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So as long as we start from a point different than the optimum we have that $d_0 > 0$ and since $1 + \\gamma^2 a^4 > 1$ for any $\\gamma > 0$ and $a \\neq 0$, the distance from the optimum diverges, and thus the sequence of iterates $\\{x^k, y^k \\}_{k=0}^\\infty$ diverges too. The rate at which the distance increases is $(1 + \\gamma^2 a^4)^{\\frac{k}{2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(Optional $\\star$)__ A second attempt at finding the solution via _alternating_ gradient descent ascent on $x$\n",
    "        and $y$. More precisely for $\\gamma > 0$ consider the update\n",
    "        \n",
    "\\begin{equation}\n",
    "    x^{k+1} = x^k - \\gamma \\nabla_x f(x^k, y^k), \\qquad\n",
    "    y^{k+1} = y^k + \\gamma \\nabla_y f(x^{k+1}, y^k) \\nonumber\n",
    "\\end{equation}\n",
    "Show that the sequence of iterates $\\{x^k, y^k \\}_{k=0}^\\infty$ starting\n",
    "from any point $(x^0, y^0) \\neq (x^\\star, y^\\star)$ i) never converges, ii) but still remains bounded under certain stepsize conditions.\n",
    "\n",
    "\n",
    "Note: in this example, for simplicity just consider $f:\\mathbb{R}^2 \\to \\mathbb{R}$ with variables $x,y$, where\n",
    "$x, y \\in \\mathbb{R}$, the function has the form of\n",
    "$\n",
    "f(x,y) = (a x - b) (a y - c), \\quad a \\neq 0, \\; b,c \\in \\mathbb{R}.\n",
    "$\n",
    "\n",
    "\n",
    "**HINT**: Reduce the problem to studying a linear system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 A concrete example: Rock - Paper - Scissors - Lizard - Spock - 40 points\n",
    "\n",
    "To make your previous abstract analysis more concrete, we will now look at the iconic Rock-Paper-Scissors-Lizard-Spock game. Sheldon and Leonard always like to settle their differences through a round of this game, whose rules they state as follows:\n",
    "\n",
    "*\"Scissors cuts Paper, Paper covers Rock, Rock crushes Lizard, Lizard poisons Spock, Spock smashes Scissors, Scissors decapitates Lizard, Lizard eats Paper, Paper disproves Spock, Spock vaporizes Rock, (and as it always has) Rock crushes Scissors\"*\n",
    "\n",
    "Sheldon and Leonard always pick to play Spock because \"logic trumps all\", it will be your task to show that this is not the optimal strategy.\n",
    "\n",
    "We can formalize the game as follows. There are two players, the `x` player (e.g. Sheldon) and the `y` player (e.g. Leonard). There is only one single round. The players play a randomized strategy: each player chooses a probability of playing rock/paper/scissors/lizard/Spock. We look at the expected pay-off of these randomized strategies. \n",
    "\n",
    "In other words, the players choose an element in $\\Delta_5$ the probability simplex in dimension 5. The `x` player chooses a vector $\\mathbf{x} = \\begin{bmatrix} \\mathbf{x}_1 & \\mathbf{x}_2 & \\mathbf{x}_3 & \\mathbf{x}_4 & \\mathbf{x}_5 \\end{bmatrix} \\in \\Delta_5$ where $\\mathbf{x}_1$ is the probability of playing `Rock`, $\\mathbf{x}_2$ is the probability of playing `Paper`, $\\mathbf{x}_3$ is the probability of playing `Scissors`, $\\mathbf{x}_4$ is the probability of playing `Lizard`, $\\mathbf{x}_5$ is the probability of playing `Spock`. The `y` player chooses a vector $\\mathbf{y} \\in \\Delta_5$ defined in the same way. \n",
    "\n",
    "The game designers decide that winning the game gives 1 point and a tie gives 0 points. So the expected payoff for a give choice of strategies $\\mathbf{x}, \\mathbf{y}$ is obtained by computing:\n",
    "$$\n",
    "\\mathbf{x}^\\top \\begin{bmatrix} 0 & 1 & -1 & -1 & 1 \\\\ -1 & 0 & 1 & 1 & -1 \\\\ 1 & -1 & 0 & -1 & 1 \\\\ 1 & -1 & 1 & 0 & -1 \\\\ -1 & 1 & -1 & 1 & 0 \\end{bmatrix}\\mathbf{y}\n",
    "$$\n",
    "\n",
    "The `x` player wants to minimize this expected payoff and the `y` player wants to maximize it. So the problem we seek to solve is\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{x} \\in \\Delta_5} \\max_{\\mathbf{y} \\in \\Delta_5} \\mathbf{x}^\\top \\mathbf{M}\\mathbf{y} =: f(\\mathbf{x}, \\mathbf{y})\n",
    "$$\n",
    "with $\\mathbf{M} = \\begin{bmatrix} 0 & 1 & -1 & -1 & 1 \\\\ -1 & 0 & 1 & 1 & -1 \\\\ 1 & -1 & 0 & -1 & 1 \\\\ 1 & -1 & 1 & 0 & -1 \\\\ -1 & 1 & -1 & 1 & 0 \\end{bmatrix}$.\n",
    "\n",
    "In the following cells, you will implement methods to solve this game and find the optimal strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ipywidgets import interact, SelectionSlider, fixed\n",
    "from itertools import combinations\n",
    "from scipy.stats import entropy\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** (2 points) Implement the objective function $f$ given two 3 dimensional vectors `x` and `y` stored as `torch.Tensor` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ???\n",
    "def f(x: torch.Tensor, y: torch.Tensor):\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** (10 points) Implement a single step of the simultaneous gradient descent/ascent studied in question 1.1.(3). Since we are in a constrained setting, make sure you include a projection step onto the simplex. \n",
    "\n",
    "The function `GDA` you will implement takes in the objective function `f`, the two current strategies of the players stored in tensors `x` and `y` and a step_size. Write the function so that it modifies the variables `x` and `y` in place without returning anything.\n",
    "\n",
    "We provide you with a function called `simplex_project` that projects a vector on the probability simplex. The function has no return value and does the projection in place. Use `Pytorch` to compute gradients automatically. \n",
    "\n",
    "__Hints__: Review what a call to `.backward()` on a tensor does. Review what in-place operations are like `.add_`. Think of which steps need to be in a `with torch.no_grad()` block. Remember to zero the gradients before re-using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDA(f, x, y, step_size):\n",
    "    payoff = f(x, y)\n",
    "    ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this algorithm initialized from Sheldon and Leonard's strategies of always playing Spock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = torch.tensor([0.0, 0.0, 0.0, 0.0, 1.0])\n",
    "y_init = torch.tensor([0.0, 0.0, 0.0, 0.0, 1.0])\n",
    "\n",
    "gda_x_sequence, gda_y_sequence = run_alg(GDA, f, x_init, y_init, step_size=0.05, n_iterations=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this sequence as ${4 \\choose 2} = 6$ two dimensional slices since the simplex $\\Delta_5$ is 4-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pairs = list(combinations(range(4), 2))\n",
    "def visualize_seq_slice(dim_pair):\n",
    "    visualize_seq(gda_x_sequence[:, dim_pairs[dim_pair]], \n",
    "                  gda_y_sequence[:, dim_pairs[dim_pair]],\n",
    "                  dim_pairs[dim_pair])\n",
    "interact(visualize_seq_slice, dim_pair=SelectionSlider(\n",
    "    options=range(len(dim_pairs)),\n",
    "    value=0,\n",
    "    description=\"Dim pair:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have plots that aggregate the convergence status over all 5 dimensions at the same time, let's also visualize:\n",
    "\n",
    "- the duality gap over time: $g_k = \\max_{\\mathbf{y} \\in \\Delta_5}{f(\\mathbf{x}_k,\\mathbf{y})} - \\min_{\\mathbf{x} \\in \\Delta_5}{f(\\mathbf{x},\\mathbf{y}_k)} = \\max_{i}{(\\mathbf{M}^\\top \\mathbf{x}_k)_i} - \\min_{i}{(\\mathbf{M} \\mathbf{y}_k)_i}$\n",
    "- the distance to the optimum over time: $d_k=\\sqrt{||\\mathbf{x}_k-\\mathbf{x}^\\star||_2^2 + ||\\mathbf{y}_k-\\mathbf{y}^\\star||_2^2}$\n",
    "- the discrete entropy over time of the x and y strategies (we can do this since they are probability distributions): $H(\\mathbf{x}_k)=-\\sum_{i=1}^{5}{\\mathbf{x}_k^{(i)}\\log{\\mathbf{x}_k^{(i)}}}, H(\\mathbf{y}_k)=-\\sum_{i=1}^{5}{\\mathbf{y}_k^{(i)}\\log{\\mathbf{y}_k^{(i)}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_opt(L_x, L_y):\n",
    "    return np.sqrt(np.sum((L_x - 0.2) ** 2 + (L_y - 0.2) ** 2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duality_gap(L_x, L_y):\n",
    "    return (np.max(M.numpy().T.reshape(1, 5, 5) @ L_x.reshape(-1, 5, 1), axis=(1, 2)) \n",
    "            - np.min(M.numpy().reshape(1, 5, 5) @ L_y.reshape(-1, 5, 1), axis=(1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-poster')\n",
    "fig, ax = plt.subplots(3, 1, figsize=(11.7, 1.5 * 8.3))\n",
    "ax[0].plot(range(len(gda_x_sequence)), entropy(gda_x_sequence, axis=1), lw=5, color='b', label=\"GDA x\")\n",
    "ax[0].plot(range(len(gda_y_sequence)), entropy(gda_y_sequence, axis=1), lw=5, color='r', label=\"GDA y\")\n",
    "ax[0].axline((0, np.log(5)), slope=0, color='black', lw=5, label=\"Max\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"k\")\n",
    "ax[0].set_ylabel(\"Entropy\")\n",
    "ax[1].plot(range(len(gda_x_sequence)), distance_to_opt(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_xlabel(\"k\")\n",
    "ax[1].set_ylabel(\"$d_k$\")\n",
    "ax[2].plot(range(len(gda_x_sequence)), duality_gap(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "ax[2].legend()\n",
    "ax[2].set_yscale(\"log\")\n",
    "ax[2].set_xlabel(\"k\")\n",
    "ax[2].set_ylabel(\"$g_k$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** (3 point) What kind of behavior do you observe ? Do the iterates converge ? Play with the step_size and the number of iterations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** (4 points) As you've shown both theoretically and in practice, simultaneous Gradient Descent Ascent (sGDA) cannot solve the problem. You will now implement algorithm that can solve bilinear games. We will denote the projection onto the decision space of the x-player and y-player, $\\Pi_{\\mathcal X}$ and $\\Pi_{\\mathcal Y}$, respectively.\n",
    "\n",
    "\n",
    "Let $\\mathbf{z}_k = \\begin{bmatrix} x_k \\\\ y_k \\end{bmatrix}$, $\\Pi(\\mathbf{z})=\\begin{bmatrix} \\Pi_{\\mathcal X}(x) \\\\ \\Pi_{\\mathcal Y}(y) \\end{bmatrix}$ and $G(\\mathbf{z}_k) = \\begin{bmatrix} \\nabla_x f(x_k,y_k) \\\\ -\\nabla_y f(x_k,y_k) \\end{bmatrix}$.\n",
    "\n",
    "Consider the following implicit updates, which is the `Proximal Point Method ` (PPM) for solving the bilinear games:\n",
    "\\begin{equation}\n",
    "    \\mathbf{z}_{k+1} = \\Pi(\\mathbf{z}_k - \\gamma G(\\color{red}{\\mathbf{z}_{k+1}})) \\nonumber\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first prove that the Proximal Point Method (PPM) converges in a simple case to build intuition. Consider the aforementioned stylized function $f: \\mathbb{R}^2 \\to \\mathbb{R}$, such that $f(x, y)=xy$, and consider simplified unconstrained probelm, i.e., the projection is the identity map. Prove that PPM converges.\n",
    "\n",
    "[Hint] Rewrite the implicit update as an explicit update in the form of $z_{k+1} = A z_{k}$ for some matrix $A$.\n",
    "\n",
    "[Hint] A square matrix $A$ satisfies $\\lim_{k \\to \\infty} A^k = 0$ if its spectral radius $\\rho(A) < 1$, where the spectral radius is defined by\n",
    "$\n",
    "\\rho(A) := \\max_i |\\lambda_i|,\n",
    "$\n",
    "with $\\{\\lambda_i\\}$ denoting the  eigenvalues of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)** (6 points)  In general, computing the next iterate $\\mathbf{z}_{k+1}$ in PPM requires you to solve a fixed point problem because we are evaluating the gradient at the unknown next iterate. As this is too costly, we circumvent this difficulty by doing an _extrapolation_ step. The idea behind `ExtraGradient` (EG) is to approximate an implicit update with a more tractable one. Define the half steps:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{z}_{k+1/2} = \\Pi(\\mathbf{z}_k - \\gamma G(\\mathbf{z}_k)) \\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "These half step extrapolation variables will help us to approximate the implicit iterates. We can then write\n",
    "\\begin{equation}\n",
    "    \\mathbf{z}_{k+1} = \\Pi(\\mathbf{z}_k - \\gamma G(\\color{green}{\\mathbf{z}_{k+1/2}})) \\nonumber\n",
    "\\end{equation}\n",
    "The recursion above defines the ExtraGradient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtraGradient(f, x, y, step_size):\n",
    "    payoff = f(x, y)\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_x_sequence, eg_y_sequence = run_alg(ExtraGradient, f, x_init, y_init, step_size=0.1, n_iterations=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pairs = list(combinations(range(4), 2))\n",
    "def visualize_seq_slice(dim_pair):\n",
    "    visualize_seq(eg_x_sequence[:, dim_pairs[dim_pair]], \n",
    "                  eg_y_sequence[:, dim_pairs[dim_pair]],\n",
    "                  dim_pairs[dim_pair])\n",
    "interact(visualize_seq_slice, dim_pair=SelectionSlider(\n",
    "    options=range(len(dim_pairs)),\n",
    "    value=0,\n",
    "    description=\"Dim pair:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-poster')\n",
    "fig, ax = plt.subplots(3, 1, figsize=(11.7, 1.5 * 8.3))\n",
    "ax[0].plot(range(len(gda_x_sequence)), entropy(gda_x_sequence, axis=1), lw=5, color='b', alpha=0.1, label=\"GDA x\")\n",
    "ax[0].plot(range(len(gda_y_sequence)), entropy(gda_y_sequence, axis=1), lw=5, color='r', alpha=0.1, label=\"GDA y\")\n",
    "ax[0].plot(range(len(eg_x_sequence)), entropy(eg_x_sequence, axis=1), lw=5, color='b', label=\"EG x\")\n",
    "ax[0].plot(range(len(eg_y_sequence)), entropy(eg_y_sequence, axis=1), lw=5, color='r', label=\"EG y\")\n",
    "ax[0].axline((0, np.log(5)), slope=0, color='black', lw=5, alpha=0.5, label=\"Max\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"k\")\n",
    "ax[0].set_ylabel(\"Entropy\")\n",
    "ax[1].plot(range(len(gda_x_sequence)), distance_to_opt(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "ax[1].plot(range(len(eg_x_sequence)), distance_to_opt(eg_x_sequence, eg_y_sequence), lw=5, label=\"EG\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_xlabel(\"k\")\n",
    "ax[1].set_ylabel(\"$d_k$\")\n",
    "ax[2].plot(range(len(gda_x_sequence)), duality_gap(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "ax[2].plot(range(len(eg_x_sequence)), duality_gap(eg_x_sequence, eg_y_sequence), lw=5, label=\"EG\")\n",
    "ax[2].legend()\n",
    "ax[2].set_yscale(\"log\")\n",
    "ax[2].set_xlabel(\"k\")\n",
    "ax[2].set_ylabel(\"$g_k$\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(BONUS)** What can you observe about the optimal solution? What properties does the optimal Rock-Paper-Scissors-Lizard-Spock strategy have? Prove that extra-gradient in the bilinear case doesn't diverge like GDA. (Again, candy reward for correct answers!)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6)** (10 points) It turns out that we can _generalize_ the ExtraGradient method naturally by striving for a bit more accurate extrapolation. Namely, instead of always performing 1 extrapolation step updating half-iterates before the main parameter update, we can perform $m\\geq 1$ fractional steps. Implement this ClairvoyantExtraGradient (CEG) method [1], with the precise update step formulas given below:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{z}_{k+1(\\color{green}{1/m+1})} = \\Pi(\\mathbf{z}_k - \\gamma G(\\color{green}{\\mathbf{z}_{k}})) \\\\\n",
    "    \\mathbf{z}_{k+1(\\color{green}{2/m+1})} = \\Pi(\\mathbf{z}_{k+1(\\color{green}{1/m+1})} - \\gamma G(\\mathbf{z}_{k+1(\\color{green}{1/m+1})})) \\\\\n",
    "    \\vdots \\\\\n",
    "    \\mathbf{z}_{k+1(\\color{green}{m/m+1})} = \\Pi(\\mathbf{z}_{k+1(\\color{green}{m-1/m+1})} - \\gamma G(\\mathbf{z}_{k+1(\\color{green}{m-1/m+1})})) \\\\\n",
    "    \\mathbf{z}_{k+1} = \\Pi(\\mathbf{z}_k - \\gamma G({\\mathbf{z}_{k+1(\\color{green}{m/m+1})} })) \\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "[1] Cevher, Volkan, Georgios Piliouras, Ryann Sim, and Stratis Skoulakis. “Min-Max Optimization Made Simple: Approximating the Proximal Point Method via Contraction Maps.” In 2023 Symposium on Simplicity in Algorithms (SOSA), 192–206. Proceedings. Society for Industrial and Applied Mathematics, 2023. https://doi.org/10.1137/1.9781611977585.ch18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClairvoyantExtraGradient(f, x, y, step_size, m=1):\n",
    "    payoff = f(x, y)\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_values = [1, 2, 3, 5, 10, 25] # You can change this if you wish\n",
    "ceg_x_sequences, ceg_y_sequences = [], []\n",
    "for m in m_values:\n",
    "    print(\"m =\", m)\n",
    "    step_size = 0.1 if m != 10 else 0.09 # You can change this if you wish\n",
    "    ceg_x_sequence, ceg_y_sequence = run_alg(ClairvoyantExtraGradient, f, x_init, y_init, \n",
    "                                             n_iterations=2500, step_size=step_size, m=m)\n",
    "    ceg_x_sequences.append(ceg_x_sequence)\n",
    "    ceg_y_sequences.append(ceg_y_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pairs = list(combinations(range(4), 2))\n",
    "def visualize_seq_slice(L_x, L_y, dim_pair):\n",
    "    visualize_seq(L_x[:, dim_pairs[dim_pair]], \n",
    "                  L_y[:, dim_pairs[dim_pair]],\n",
    "                  dim_pairs[dim_pair])\n",
    "for m, ceg_x_sequence, ceg_y_sequence in zip(m_values, ceg_x_sequences, ceg_y_sequences):\n",
    "    print(\"m =\", m)\n",
    "    interact(visualize_seq_slice, L_x=fixed(ceg_x_sequence), L_y=fixed(ceg_y_sequence), dim_pair=SelectionSlider(\n",
    "        options=range(len(dim_pairs)),\n",
    "        value=0,\n",
    "        description=\"Dim pair:\",\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-poster')\n",
    "fig, ax = plt.subplots(3, 1, figsize=(11.7, 1.5 * 8.3))\n",
    "ax[0].plot(range(len(gda_x_sequence)), entropy(gda_x_sequence, axis=1), lw=5, alpha=0.1, label=\"GDA x\")\n",
    "ax[1].plot(range(len(gda_x_sequence)), distance_to_opt(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "ax[2].plot(range(len(gda_x_sequence)), duality_gap(gda_x_sequence, gda_y_sequence), lw=5, label=\"GDA\")\n",
    "for m, ceg_x_sequence, ceg_y_sequence in zip(m_values, ceg_x_sequences, ceg_y_sequences):\n",
    "    ax[0].plot(range(len(ceg_x_sequence)), entropy(ceg_x_sequence, axis=1), lw=5, label=f\"CEG-{m} x\")\n",
    "    ax[1].plot(range(len(ceg_x_sequence)), distance_to_opt(ceg_x_sequence, ceg_y_sequence), lw=5, label=f\"CEG-{m}\")\n",
    "    ax[2].plot(range(len(ceg_x_sequence)), duality_gap(ceg_x_sequence, ceg_y_sequence), lw=5, label=f\"CEG-{m}\")\n",
    "ax[0].axline((0, np.log(5)), slope=0, color='black', lw=5, alpha=0.5, label=\"Max\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"k\")\n",
    "ax[0].set_ylabel(\"Entropy\")\n",
    "ax[1].legend()\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_xlabel(\"k\")\n",
    "ax[1].set_ylabel(\"$d_k$\")\n",
    "ax[2].legend()\n",
    "ax[2].set_yscale(\"log\")\n",
    "ax[2].set_xlabel(\"k\")\n",
    "ax[2].set_ylabel(\"$g_k$\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(7)** (5 points) Discuss what you observe for the CEG runs. How do the value of $m$ and the step size influence the convergence and the computation cost? Is there a sweet spot?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:light,ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
